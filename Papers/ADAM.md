# ADAM: A method for stochastic optimization. 

ADAM - Adaptive moment estimation. 

* Computes individual adaptive learning rates for different parameters from estimates of first and second moments of the gradients. 

> What is a moment?
> The nth moment of a function f(x) about a value c is given as  $$\mu_n=\int_{-\infty}^\infty(x-c)^nf(x)dx$$
> First moment then implies mean
> Second moment implies variance.



# YOLOX: Exceeding YOLO Series in 2021

## Metadata

* Item Type: [Article](article)
* Authors: [[Zheng Ge]], [[Songtao Liu]], [[Feng Wang]], [[Zeming Li]], [[Jian Sun]]
* Date: [2021/07/18](2021/07/18)
* Date Added: [2022-04-20](2022-04-20)
* URL: [https://arxiv.org/abs/2107.08430v2](https://arxiv.org/abs/2107.08430v2)
* DOI: [10.48550/arXiv.2107.08430](https://doi.org/10.48550/arXiv.2107.08430)
* Cite key: undefined
* Topics: [[Object Detection]]
, #zotero, #literature-notes, #reference
* PDF Attachments
	- [Full Text PDF](zotero://open-pdf/library/items/TWF6YSTT)

## Abstract

In this report, we present some experienced improvements to YOLO series, forming a new high-performance detector -- YOLOX. We switch the YOLO detector to an anchor-free manner and conduct other advanced detection techniques, i.e., a decoupled head and the leading label assignment strategy SimOTA to achieve state-of-the-art results across a large scale range of models: For YOLO-Nano with only 0.91M parameters and 1.08G FLOPs, we get 25.3% AP on COCO, surpassing NanoDet by 1.8% AP; for YOLOv3, one of the most widely used detectors in industry, we boost it to 47.3% AP on COCO, outperforming the current best practice by 3.0% AP; for YOLOX-L with roughly the same amount of parameters as YOLOv4-CSP, YOLOv5-L, we achieve 50.0% AP on COCO at a speed of 68.9 FPS on Tesla V100, exceeding YOLOv5-L by 1.8% AP. Further, we won the 1st Place on Streaming Perception Challenge (Workshop on Autonomous Driving at CVPR 2021) using a single YOLOX-L model. We hope this report can provide useful experience for developers and researchers in practical scenes, and we also provide deploy versions with ONNX, TensorRT, NCNN, and Openvino supported. Source code is at https://github.com/Megvii-BaseDetection/YOLOX.


##  Zotero links
* [Local library](zotero://select/items/1_RN5355LC)
* [Cloud library](http://zotero.org/users/local/w9KcQm7A/items/RN5355LC)

